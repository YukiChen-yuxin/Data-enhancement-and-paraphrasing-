{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c27e2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cacea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/yuki/Desktop/大创/数据/data_para_extra_dic111.json',encoding=\"utf-8\") as file_obj:\n",
    "    data_para_extra=json.load(file_obj)\n",
    "    \n",
    "with open('C:/Users/yuki/Desktop/大创/数据/data_extra_dic2.json',encoding=\"utf-8\") as file_obj:\n",
    "    data_extra_dic2=json.load(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1061efe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_para_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f4234dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sen=[]\n",
    "for dic in data_para_extra:\n",
    "    s=''.join(dic['原句子'])\n",
    "    sen.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d07bec9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49890"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_extra_dic2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac3b6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhanlp import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea3f4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_extra2=[]\n",
    "for i in sen:\n",
    "    text=HanLP.segment(i)\n",
    "    test=text.toArray()\n",
    "    temp=[]\n",
    "    for i in test:\n",
    "        temp.append(i.toString())\n",
    "    data_extra2.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c426fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#按照词性标注2挖句子模板\n",
    "data_extra_dic22=[]\n",
    "for item in data_extra2:\n",
    "    temp={}\n",
    "    lst=[]\n",
    "    extra=[]\n",
    "    for i in item:\n",
    "        if ('/n' == i[-2:]) or ('/i' == i[-2:]) or ('/a' == i[-2:]) or ('/vn' == i[-3:]):\n",
    "            lst.append('moudle')\n",
    "            extra.append(i.split('/'))\n",
    "        else:\n",
    "            lst.append(i.split('/')[0])\n",
    "    temp['原句']=item\n",
    "    temp['抽取的句子']=lst\n",
    "    temp['抽取的词']=extra\n",
    "    data_extra_dic22.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c6d9bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_extra_dic22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b8760ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='C:/Users/yuki/Desktop/大创/数据/data_extra_dic22.json'\n",
    "with open(filename,'w',encoding='utf-8') as file_obj:\n",
    "    json.dump(data_extra_dic22,file_obj,ensure_ascii=False,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cfe6bbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open('C:/Users/yuki/Desktop/大创/数据/senten.txt','w',encoding='utf-8')\n",
    "for line in sen:\n",
    "    for i in line:\n",
    "        f.write(i+' ')\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d392500",
   "metadata": {},
   "outputs": [],
   "source": [
    "fenci=[]\n",
    "for i in data_extra_dic22:\n",
    "    temp=i['原句']\n",
    "    tt=[]\n",
    "    for word in temp:\n",
    "        if len(word.split('/'))!=2:\n",
    "            tt.append(word[:-2])\n",
    "        else:\n",
    "            tt.append(word.split('/')[0])\n",
    "    fenci.append(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9529163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='C:/Users/yuki/Desktop/大创/数据/fenci_22.json'\n",
    "with open(filename,'w',encoding='utf-8') as file_obj:\n",
    "    json.dump(fenci,file_obj,ensure_ascii=False,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048f12a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
